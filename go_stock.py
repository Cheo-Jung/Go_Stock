"""
ì£¼ì‹/ì½”ì¸ ê°€ê²© ë° ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì—°ë™í•˜ì—¬ ìƒˆë¡œìš´ ê°€ê²©ì„ ìƒì„±í•˜ëŠ” í”„ë¡œê·¸ë¨
LLM/Transformer ê¸°ë°˜ ì‹œê³„ì—´ ìƒì„± ëª¨ë¸
"""

from __future__ import annotations

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from transformers import AutoTokenizer, AutoModel
from datetime import datetime, timedelta
import yfinance as yf
import requests
from typing import List, Dict, Tuple, Optional
import json
import os
import warnings
warnings.filterwarnings('ignore')

# .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ (python-dotenv ì„¤ì¹˜ ì‹œ)
# ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ .env ì°¾ê¸° (ì‹¤í–‰ ê²½ë¡œì— ìƒê´€ì—†ì´ ë™ì‘)
_env_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '.env')

def _load_env_fallback():
    """load_dotenvê°€ ì•ˆ ë  ë•Œ .env ì§ì ‘ íŒŒì‹± (BOM/ì¸ì½”ë”©/\\r ëŒ€ë¹„). Colab: /content, cwdë„ í™•ì¸."""
    want = ('NEWSAPI_KEY', 'ALPHAVANTAGE_API_KEY', 'FINNHUB_API_KEY')
    if all(os.getenv(k) for k in want):
        return
    _bom = chr(0xFEFF)
    paths = [
        _env_path,
        '/content/.env',  # Google Colab ê¸°ë³¸
        os.path.join(os.getcwd(), '.env'),
    ]
    for p in paths:
        if not p or not os.path.isfile(p):
            continue
        raw = None
        for enc in ('utf-8-sig', 'utf-8', 'cp949', 'latin-1'):
            try:
                with open(p, 'r', encoding=enc) as f:
                    raw = f.read()
                break
            except Exception:
                continue
        if raw is None:
            continue
        for line in raw.replace('\r\n', '\n').replace('\r', '\n').split('\n'):
            line = line.strip().replace(_bom, '')
            if not line or line.startswith('#') or '=' not in line:
                continue
            k, v = line.split('=', 1)
            k = k.strip().replace(_bom, '').replace('\r', '').strip()
            v = v.strip().strip('"').strip("'").replace('\r', '').strip()
            if k in want and not os.getenv(k) and v:
                os.environ[k] = v
        if all(os.getenv(k) for k in want):
            break

try:
    from dotenv import load_dotenv
    load_dotenv(_env_path)
    load_dotenv()
    # Colab: ì—…ë¡œë“œí•œ .envê°€ /content ë˜ëŠ” cwdì— ìˆëŠ” ê²½ìš°
    for p in ('/content/.env', os.path.join(os.getcwd(), '.env')):
        if p and p != _env_path and os.path.isfile(p):
            load_dotenv(p)
            break
except ImportError:
    pass
_load_env_fallback()


class PriceNewsDataset(Dataset):
    """ê°€ê²©ê³¼ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ê²°í•©í•œ ë°ì´í„°ì…‹"""
    
    # ì§€ì›ë˜ëŠ” ëª¨ë¸ê³¼ ì„ë² ë”© ì°¨ì›
    MODEL_CONFIGS = {
        'fine5': {
            'name': 'intfloat/e5-mistral-7b-instruct',
            'embedding_dim': 4096,
            'description': 'Fin-E5 - ìµœê³  ì„±ëŠ¥ ê¸ˆìœµ ì„ë² ë”© ëª¨ë¸ (16GB+ GPU í•„ìš”, Colab ê¶Œì¥)'
        },
        'finbert': {
            'name': 'ProsusAI/finbert',
            'embedding_dim': 768,
            'description': 'FinBERT - ê¸ˆìœµ í…ìŠ¤íŠ¸ì— ìµœì í™”ëœ ëª¨ë¸ (ê¶Œì¥)'
        },
        'distilbert': {
            'name': 'distilbert-base-uncased',
            'embedding_dim': 768,
            'description': 'DistilBERT - ë” ë¹ ë¥´ê³  ì‘ì€ ëª¨ë¸'
        },
        'bert': {
            'name': 'bert-base-uncased',
            'embedding_dim': 768,
            'description': 'BERT - ë²”ìš© ëª¨ë¸'
        },
        'roberta': {
            'name': 'roberta-base',
            'embedding_dim': 768,
            'description': 'RoBERTa - ê°œì„ ëœ BERT'
        }
    }
    
    def __init__(self, price_data: pd.DataFrame, news_data: List[Dict], 
                 sequence_length: int = 60, prediction_length: int = 1,
                 device: Optional[torch.device] = None,
                 embedding_model: str = 'finbert'):
        """
        Args:
            price_data: ì‹œê³„ì—´ ê°€ê²© ë°ì´í„° (datetime, open, high, low, close, volume)
            news_data: ë‰´ìŠ¤ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ [{timestamp, title, content, sentiment}, ...]
            sequence_length: ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ (ê³¼ê±° ëª‡ ê°œì˜ ì‹œê°„ ë‹¨ìœ„ë¥¼ ë³¼ì§€)
            prediction_length: ì˜ˆì¸¡í•  ë¯¸ë˜ ê¸¸ì´
            device: GPU/CPU ì¥ì¹˜ (Noneì´ë©´ ìë™ ê°ì§€)
            embedding_model: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ ('fine5', 'finbert', 'distilbert', 'bert', 'roberta')
        """
        self.sequence_length = sequence_length
        self.prediction_length = prediction_length
        self.price_data = price_data.sort_values('datetime').reset_index(drop=True)
        self.news_data = sorted(news_data, key=lambda x: x['timestamp'])
        
        # ì¥ì¹˜ ì„¤ì •
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = device
        
        # ê°€ê²© ë°ì´í„° ì •ê·œí™”
        self.price_mean = self.price_data[['open', 'high', 'low', 'close', 'volume']].mean()
        self.price_std = self.price_data[['open', 'high', 'low', 'close', 'volume']].std()
        self.normalized_prices = (self.price_data[['open', 'high', 'low', 'close', 'volume']] 
                                  - self.price_mean) / (self.price_std + 1e-8)
        
        # ì„ë² ë”© ëª¨ë¸ ì„¤ì •
        embedding_model = embedding_model.lower()
        if embedding_model not in self.MODEL_CONFIGS:
            print(f"âš  ê²½ê³ : '{embedding_model}' ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'finbert'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            embedding_model = 'finbert'
        
        config = self.MODEL_CONFIGS[embedding_model]
        model_name = config['name']
        self.embedding_dim = config['embedding_dim']
        
        print(f"ğŸ“ ì„ë² ë”© ëª¨ë¸ ë¡œë”©: {config['description']}")
        print(f"   ëª¨ë¸: {model_name}")
        
        # ë‰´ìŠ¤ ì„ë² ë”©ì„ ìœ„í•œ ëª¨ë¸ ë¡œë“œ
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            # Fin-E5ëŠ” Instruct ëª¨ë¸ì´ì§€ë§Œ AutoModelë¡œ ì„ë² ë”© ì¶”ì¶œ ê°€ëŠ¥
            self.news_model = AutoModel.from_pretrained(model_name)
            self.news_model.to(self.device)
            self.news_model.eval()
            print(f"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì„ë² ë”© ì°¨ì›: {self.embedding_dim})")
        except Exception as e:
            print(f"âš  ê²½ê³ : {model_name} ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("   'bert-base-uncased'ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')
            self.news_model = AutoModel.from_pretrained('bert-base-uncased')
            self.news_model.to(self.device)
            self.news_model.eval()
            self.embedding_dim = 768
        
        # ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì‹œê°„ë³„ë¡œ ê·¸ë£¹í™”
        self.news_by_time = self._group_news_by_time()
        
    def _group_news_by_time(self) -> Dict:
        """ë‰´ìŠ¤ë¥¼ ì‹œê°„ë³„ë¡œ ê·¸ë£¹í™”"""
        news_dict = {}
        for news in self.news_data:
            time_key = pd.to_datetime(news['timestamp']).floor('H')  # ì‹œê°„ ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”
            if time_key not in news_dict:
                news_dict[time_key] = []
            news_dict[time_key].append(news)
        return news_dict
    
    def _get_news_embedding(self, news_list: List[Dict]) -> torch.Tensor:
        """ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ì˜ í‰ê·  ì„ë² ë”© ê³„ì‚°"""
        if not news_list:
            return torch.zeros(self.embedding_dim, device=self.device)
        
        texts = [f"{n.get('title', '')} {n.get('content', '')[:200]}" for n in news_list]
        embeddings = []
        
        with torch.no_grad():
            for text in texts:
                inputs = self.tokenizer(text, return_tensors='pt', truncation=True, 
                                       max_length=128, padding='max_length')
                # ì…ë ¥ì„ GPUë¡œ ì´ë™
                inputs = {k: v.to(self.device) for k, v in inputs.items()}
                outputs = self.news_model(**inputs)
                # [CLS] í† í°ì˜ ì„ë² ë”© ì‚¬ìš©
                embeddings.append(outputs.last_hidden_state[0, 0, :])
        
        result = torch.stack(embeddings).mean(dim=0)
        # CPUë¡œ ì´ë™ (DataLoaderê°€ CPUì—ì„œ ì‘ë™í•˜ë¯€ë¡œ)
        return result.cpu()
    
    def __len__(self):
        return len(self.price_data) - self.sequence_length - self.prediction_length + 1
    
    def __getitem__(self, idx):
        # ê°€ê²© ì‹œí€€ìŠ¤ ì¶”ì¶œ
        price_seq = self.normalized_prices.iloc[idx:idx+self.sequence_length].values
        target_idx = idx + self.sequence_length
        target_price = self.normalized_prices.iloc[target_idx:target_idx+self.prediction_length]['close'].values
        
        # í•´ë‹¹ ì‹œê°„ëŒ€ì˜ ë‰´ìŠ¤ ì„ë² ë”© ì¶”ì¶œ
        time_key = pd.to_datetime(self.price_data.iloc[target_idx]['datetime']).floor('H')
        news_list = self.news_by_time.get(time_key, [])
        news_embedding = self._get_news_embedding(news_list)
        
        return {
            'price_sequence': torch.FloatTensor(price_seq),
            'news_embedding': news_embedding,
            'target': torch.FloatTensor(target_price)
        }


class PriceNewsGenerator(nn.Module):
    """ê°€ê²©ê³¼ ë‰´ìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ìƒˆë¡œìš´ ê°€ê²©ì„ ìƒì„±í•˜ëŠ” ëª¨ë¸"""
    
    def __init__(self, price_features: int = 5, news_embedding_dim: int = 768,
                 hidden_dim: int = 256, num_layers: int = 4, num_heads: int = 8):
        super(PriceNewsGenerator, self).__init__()
        
        # ê°€ê²© ì‹œí€€ìŠ¤ ì¸ì½”ë” (Transformer)
        self.price_encoder = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(
                d_model=hidden_dim,
                nhead=num_heads,
                dim_feedforward=hidden_dim * 4,
                dropout=0.1,
                batch_first=True
            ),
            num_layers=num_layers
        )
        
        # ê°€ê²© ì…ë ¥ í”„ë¡œì ì…˜
        self.price_projection = nn.Linear(price_features, hidden_dim)
        
        # ë‰´ìŠ¤ ì„ë² ë”© í”„ë¡œì ì…˜
        self.news_projection = nn.Linear(news_embedding_dim, hidden_dim)
        
        # ë””ì½”ë” (ê°€ê²© ìƒì„±)
        self.decoder = nn.TransformerDecoder(
            nn.TransformerDecoderLayer(
                d_model=hidden_dim,
                nhead=num_heads,
                dim_feedforward=hidden_dim * 4,
                dropout=0.1,
                batch_first=True
            ),
            num_layers=num_layers
        )
        
        # ì¶œë ¥ ë ˆì´ì–´
        self.output_layer = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, 1)  # ê°€ê²© ì˜ˆì¸¡
        )
        
        # ìœ„ì¹˜ ì¸ì½”ë”©
        self.pos_encoder = nn.Parameter(torch.randn(1, 1000, hidden_dim))
        
    def forward(self, price_sequence: torch.Tensor, news_embedding: torch.Tensor):
        """
        Args:
            price_sequence: [batch_size, seq_len, price_features]
            news_embedding: [batch_size, news_embedding_dim]
        """
        batch_size, seq_len, _ = price_sequence.shape
        
        # ê°€ê²© ì‹œí€€ìŠ¤ ì¸ì½”ë”©
        price_encoded = self.price_projection(price_sequence)  # [B, L, H]
        price_encoded = price_encoded + self.pos_encoder[:, :seq_len, :]
        encoded = self.price_encoder(price_encoded)
        
        # ë‰´ìŠ¤ ì„ë² ë”©ì„ ì‹œí€€ìŠ¤ í˜•íƒœë¡œ í™•ì¥
        news_encoded = self.news_projection(news_embedding)  # [B, H]
        news_encoded = news_encoded.unsqueeze(1).expand(-1, seq_len, -1)  # [B, L, H]
        
        # ê°€ê²©ê³¼ ë‰´ìŠ¤ ì •ë³´ ê²°í•©
        combined = encoded + news_encoded
        
        # ë””ì½”ë”© (ìê¸°íšŒê·€ì  ìƒì„±)
        # ë§ˆì§€ë§‰ ì¸ì½”ë”©ëœ ì‹œí€€ìŠ¤ë¥¼ ë””ì½”ë” ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©
        decoder_input = combined[:, -1:, :]  # [B, 1, H]
        outputs = []
        
        for _ in range(1):  # prediction_lengthë§Œí¼ ìƒì„±
            decoded = self.decoder(decoder_input, combined)  # [B, 1, H]
            output = self.output_layer(decoded[:, -1:, :])  # [B, 1, 1]
            outputs.append(output)
            # ë‹¤ìŒ ë°˜ë³µì„ ìœ„í•œ ì…ë ¥ (ì‹¤ì œë¡œëŠ” range(1)ì´ë¯€ë¡œ ì‚¬ìš©ë˜ì§€ ì•Šì§€ë§Œ ì°¨ì› ë§ì¶¤)
            # decoder_inputì€ ê·¸ëŒ€ë¡œ ìœ ì§€ (ë‹¤ìŒ ì˜ˆì¸¡ ì‹œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)
        
        return torch.cat(outputs, dim=1)  # [B, 1, 1]


class StockPriceGenerator:
    """ì£¼ì‹/ì½”ì¸ ê°€ê²© ìƒì„±ê¸° ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, model_path: Optional[str] = None, embedding_model: str = 'finbert'):
        """
        Args:
            model_path: ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œ (Noneì´ë©´ ìƒˆë¡œ ìƒì„±)
            embedding_model: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ ('fine5', 'finbert', 'distilbert', 'bert', 'roberta')
                             - 'fine5': ìµœê³  ì„±ëŠ¥ ê¸ˆìœµ ì„ë² ë”© (16GB+ GPU í•„ìš”, Colab ê¶Œì¥)
                             - 'finbert': ê¸ˆìœµ í…ìŠ¤íŠ¸ì— ìµœì í™” (ê¶Œì¥, ê¸°ë³¸ê°’)
                             - 'distilbert': ë” ë¹ ë¥´ê³  ì‘ì€ ëª¨ë¸
                             - 'bert': ë²”ìš© BERT ëª¨ë¸
                             - 'roberta': ê°œì„ ëœ BERT
        """
        self.model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.price_mean = None
        self.price_std = None
        self.embedding_model = embedding_model.lower()
        
        # GPU ì •ë³´ ì¶œë ¥
        if torch.cuda.is_available():
            print(f"âœ“ GPU ê°ì§€ë¨: {torch.cuda.get_device_name(0)}")
            print(f"  CUDA ë²„ì „: {torch.version.cuda}")
            print(f"  GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
        else:
            print("âš  GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            print("  ë” ë¹ ë¥¸ í•™ìŠµì„ ìœ„í•´ Google Colab ì‚¬ìš©ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¶œë ¥
        if self.embedding_model in PriceNewsDataset.MODEL_CONFIGS:
            config = PriceNewsDataset.MODEL_CONFIGS[self.embedding_model]
            print(f"ğŸ“ ì„ë² ë”© ëª¨ë¸: {config['description']}")
        else:
            print(f"âš  ê²½ê³ : '{embedding_model}' ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'finbert'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.embedding_model = 'finbert'
        
        if model_path:
            self.load_model(model_path)
    
    def collect_price_data(self, symbol: str, period: str = '1y', interval: str = '1h') -> pd.DataFrame:
        """yfinanceë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ (ìë™ fallback í¬í•¨)"""
        import sys
        from io import StringIO
        
        print(f"ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ ì¤‘: {symbol} (period={period}, interval={interval})")
        ticker = yf.Ticker(symbol)
        data = pd.DataFrame()
        
        # yfinance ê²½ê³ ë¥¼ ì„ì‹œë¡œ ì–µì œí•˜ê³  ì¶œë ¥ ìº¡ì²˜
        old_stdout = sys.stdout
        sys.stdout = StringIO()
        
        # ì‹œë„í•  ì¡°í•© ë¦¬ìŠ¤íŠ¸ (ìš°ì„ ìˆœìœ„ ìˆœì„œ)
        attempts = [
            (period, interval),  # ì›ë˜ ìš”ì²­
        ]
        
        # fallback ì¡°í•© ì¶”ê°€ - í•­ìƒ ì‘ë™í•  ë§Œí•œ ì¡°í•©ë“¤ì„ í¬í•¨
        if interval == '1h':
            attempts.extend([
                ('1mo', '1d'),    # ê°€ì¥ ì•ˆì •ì ì¸ ì¡°í•© ë¨¼ì €
                ('3mo', '1d'),
                ('6mo', '1d'),
                (period, '1d'),   # 1h -> 1dë¡œ ë³€ê²½
                ('6mo', interval), # periodë§Œ ì¤„ì„
                ('3mo', interval),
                ('1mo', interval),
                (period, '1wk'),
            ])
        elif interval in ['5m', '15m', '30m', '60m']:
            attempts.extend([
                ('1mo', '1d'),    # ê°€ì¥ ì•ˆì •ì ì¸ ì¡°í•©
                (period, '1h'),
                (period, '1d'),
                ('1mo', interval),
            ])
        else:
            attempts.extend([
                ('1mo', '1d'),    # ê°€ì¥ ì•ˆì •ì ì¸ ì¡°í•©
                ('3mo', '1d'),
                ('6mo', '1d'),
                (period, '1d'),
                (period, '1wk'),
            ])
        
        # ê° ì¡°í•© ì‹œë„
        last_error = None
        for attempt_period, attempt_interval in attempts:
            try:
                sys.stdout = StringIO()  # ì¶œë ¥ ì´ˆê¸°í™”
                temp_data = ticker.history(period=attempt_period, interval=attempt_interval)
                output = sys.stdout.getvalue()
                sys.stdout = old_stdout
                
                # ê²½ê³  ë©”ì‹œì§€ í™•ì¸
                if 'No data found' in output or temp_data.empty or len(temp_data) == 0:
                    if attempt_period != period or attempt_interval != interval:
                        print(f"  [ê²½ê³ ] {attempt_interval}/{attempt_period} ì¡°í•© ì‹¤íŒ¨, ë‹¤ìŒ ì‹œë„ ì¤‘...")
                    continue
                
                # ì„±ê³µí•œ ê²½ìš°
                data = temp_data
                if attempt_period != period or attempt_interval != interval:
                    print(f"  [ì„±ê³µ] {attempt_interval}/{attempt_period} ì¡°í•©ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ!")
                break
                
            except Exception as e:
                sys.stdout = old_stdout
                last_error = str(e)
                if attempt_period != period or attempt_interval != interval:
                    print(f"  [ê²½ê³ ] {attempt_interval}/{attempt_period} ì¡°í•© ì‹¤íŒ¨: {str(e)[:50]}")
                continue
        
        # stdout ë³µì›
        if sys.stdout != old_stdout:
            sys.stdout = old_stdout
        
        if data.empty or len(data) == 0:
            raise ValueError(
                f"{symbol}: ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                f"**ê°€ëŠ¥í•œ ì›ì¸:**\n"
                f"1. ì‹¬ë³¼ì´ ì˜ëª»ë˜ì—ˆê±°ë‚˜ ìƒì¥íì§€ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n"
                f"2. ì„ íƒí•œ ê¸°ê°„({period})ê³¼ ê°„ê²©({interval}) ì¡°í•©ì´ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤\n"
                f"   - 1h ê°„ê²©: ìµœëŒ€ 60ì¼ (ê¶Œì¥: 1mo ê¸°ê°„)\n"
                f"   - 1d ê°„ê²©: ì œí•œ ì—†ìŒ (ê¶Œì¥)\n"
                f"3. ì¸í„°ë„· ì—°ê²° ë˜ëŠ” yahoo finance ì„œë²„ ë¬¸ì œ\n\n"
                f"**ê¶Œì¥ ì„¤ì •:**\n"
                f"- ê°„ê²©: 1d (ì¼ë´‰)\n"
                f"- ê¸°ê°„: 1y"
            )
        
        data.reset_index(inplace=True)
        # ì»¬ëŸ¼ëª… ì •ê·œí™” (ë‹¤ì–‘í•œ yfinance ë²„ì „ ëŒ€ì‘)
        if isinstance(data.columns, pd.MultiIndex):
            data.columns = data.columns.droplevel(0) if len(data.columns.levels) > 1 else data.columns
        
        data.columns = [col.lower().replace(' ', '_').replace('-', '_') for col in data.columns]
        
        # 'adj_close' ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ 'close'ë¥¼ ë³µì‚¬ (yfinance ë²„ì „ë³„ ì°¨ì´ ëŒ€ì‘)
        if 'adj_close' not in data.columns and 'close' in data.columns:
            data['adj_close'] = data['close']
        
        # Datetime ì»¬ëŸ¼ ì´ë¦„ ì²˜ë¦¬ (ë‹¤ì–‘í•œ ê²½ìš° ëŒ€ì‘)
        if 'date' in data.columns:
            data.rename(columns={'date': 'datetime'}, inplace=True)
        elif 'index' in data.columns:
            data.rename(columns={'index': 'datetime'}, inplace=True)
        elif 'datetime' not in data.columns:
            # ì¸ë±ìŠ¤ê°€ ì´ë¯¸ datetimeì´ë©´ ìƒˆë¡œ ìƒì„±
            if isinstance(data.index, pd.DatetimeIndex):
                data.insert(0, 'datetime', data.index)
            else:
                data.insert(0, 'datetime', pd.to_datetime(data.index))
        
        print(f"[ì™„ë£Œ] ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(data)}ê°œ ë ˆì½”ë“œ")
        return data
    
    def collect_news_data(self, symbol: str, days: int = 365, 
                         news_source: str = 'yfinance') -> List[Dict]:
        """
        ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
        
        Args:
            symbol: ì¢…ëª© ì‹¬ë³¼ (ì˜ˆ: 'BTC-USD', 'AAPL')
            days: ìˆ˜ì§‘í•  ì¼ìˆ˜
            news_source: ë‰´ìŠ¤ ì†ŒìŠ¤ ('yfinance', 'newsapi', 'alphavantage', 'finnhub')
        
        Returns:
            ë‰´ìŠ¤ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ [{timestamp, title, content, sentiment}, ...]
        """
        print(f"ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì¤‘: {symbol} (ì†ŒìŠ¤: {news_source})")
        
        news_list = []
        
        try:
            if news_source == 'yfinance':
                news_list = self._fetch_news_yfinance(symbol, days)
            elif news_source == 'newsapi':
                news_list = self._fetch_news_newsapi(symbol, days)
            elif news_source == 'alphavantage':
                news_list = self._fetch_news_alphavantage(symbol, days)
            elif news_source == 'finnhub':
                news_list = self._fetch_news_finnhub(symbol, days)
            else:
                print(f"âš  ê²½ê³ : ì•Œ ìˆ˜ ì—†ëŠ” ë‰´ìŠ¤ ì†ŒìŠ¤ '{news_source}'. yfinanceë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                news_list = self._fetch_news_yfinance(symbol, days)
        except Exception as e:
            print(f"âš  ê²½ê³ : {news_source}ì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            print("   yfinanceë¡œ ì¬ì‹œë„ ì¤‘...")
            try:
                news_list = self._fetch_news_yfinance(symbol, days)
            except Exception as e2:
                print(f"âš  yfinanceë„ ì‹¤íŒ¨: {e2}")
                news_list = []
        
        print(f"âœ“ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(news_list)}ê°œ")
        return news_list
    
    def _fetch_news_yfinance(self, symbol: str, days: int) -> List[Dict]:
        """yfinanceë¥¼ ì‚¬ìš©í•œ ë‰´ìŠ¤ ìˆ˜ì§‘ (ë¬´ë£Œ, API í‚¤ ë¶ˆí•„ìš”)"""
        news_list = []
        
        try:
            ticker = yf.Ticker(symbol)
            news = getattr(ticker, 'news', None)
            if news is None:
                news = []
            if not isinstance(news, list):
                news = list(news) if news else []
            
            for item in news:
                try:
                    pt = item.get('providerPublishTime') or 0
                    if not pt or pt <= 0:
                        pt = int(datetime.now().timestamp())
                    timestamp = datetime.fromtimestamp(int(pt))
                    if (datetime.now() - timestamp).days > days:
                        continue
                    title = item.get('title', '') or item.get('headline', '')
                    if not title:
                        continue
                    news_list.append({
                        'timestamp': timestamp.isoformat(),
                        'title': title,
                        'content': item.get('summary', '') or item.get('description', '') or title,
                        'sentiment': 0,
                        'source': item.get('publisher', '') or item.get('source', 'Unknown'),
                        'url': item.get('link', '') or item.get('url', '')
                    })
                except Exception:
                    continue
        except Exception as e:
            print(f"  yfinance ë‰´ìŠ¤ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        
        return news_list
    
    def _fetch_news_newsapi(self, symbol: str, days: int) -> List[Dict]:
        """NewsAPIë¥¼ ì‚¬ìš©í•œ ë‰´ìŠ¤ ìˆ˜ì§‘ (API í‚¤ í•„ìš”)"""
        news_list = []
        
        # API í‚¤ í™•ì¸ (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸° - ì½”ë“œì— ì§ì ‘ ì ì§€ ë§ˆì„¸ìš”!)
        api_key = (os.getenv('NEWSAPI_KEY', '') or '').strip()
        if not api_key:
            print("  âš  NEWSAPI_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("     ë¬´ë£Œ API í‚¤ëŠ” https://newsapi.org/register ì—ì„œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return news_list
        
        try:
            # ì‹¬ë³¼ì—ì„œ ì¢…ëª©ëª… ì¶”ì¶œ (ì˜ˆ: BTC-USD -> Bitcoin)
            query = symbol.replace('-USD', '').replace('-', ' ')
            
            # NewsAPI í˜¸ì¶œ
            url = f"https://newsapi.org/v2/everything"
            params = {
                'q': f"{query} OR {symbol}",
                'language': 'en',
                'sortBy': 'publishedAt',
                'pageSize': 100,
                'apiKey': api_key
            }
            
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            
            if data.get('status') == 'ok':
                for article in data.get('articles', []):
                    try:
                        timestamp = datetime.fromisoformat(
                            article['publishedAt'].replace('Z', '+00:00')
                        )
                        
                        if (datetime.now(timestamp.tzinfo) - timestamp).days <= days:
                            news_list.append({
                                'timestamp': timestamp.isoformat(),
                                'title': article.get('title', ''),
                                'content': article.get('description', '') or article.get('title', ''),
                                'sentiment': 0,
                                'source': article.get('source', {}).get('name', 'Unknown'),
                                'url': article.get('url', '')
                            })
                    except Exception as e:
                        continue
        except Exception as e:
            print(f"  NewsAPI ì˜¤ë¥˜: {e}")
        
        return news_list
    
    @staticmethod
    def _parse_av_time(s: str):
        """Alpha Vantage time_published íŒŒì‹±. ì˜ˆ: 20240410T013000, 2024-04-10T01:30:00Z"""
        if not s or not isinstance(s, str):
            return None
        s = s.strip().replace('Z', '+00:00')
        try:
            # ISO: 2024-04-10T01:30:00 ë˜ëŠ” 2024-04-10T01:30:00+00:00
            return datetime.fromisoformat(s)
        except Exception:
            pass
        try:
            # compact: 20240410T013000 ë˜ëŠ” 20240410T013000-0500
            s0 = s[:15] if (len(s) >= 15 and s[8:9] == 'T') else s
            if len(s0) == 15 and s0[:8].isdigit() and s0[9:15].isdigit():
                return datetime(int(s0[0:4]), int(s0[4:6]), int(s0[6:8]), int(s0[9:11]), int(s0[11:13]), int(s0[13:15]))
        except Exception:
            pass
        return None
    
    def _fetch_news_alphavantage(self, symbol: str, days: int) -> List[Dict]:
        """Alpha Vantage NEWS_SENTIMENT API ì‚¬ìš© (API í‚¤ í•„ìš”)"""
        news_list = []
        
        api_key = os.getenv('ALPHAVANTAGE_API_KEY', '')
        if not api_key:
            print("  âš  ALPHAVANTAGE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("     ë¬´ë£Œ API í‚¤ëŠ” https://www.alphavantage.co/support/#api-key ì—ì„œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return news_list
        
        try:
            # ì‹¬ë³¼ì—ì„œ í‹°ì»¤ ì¶”ì¶œ (ì˜ˆ: BTC-USD -> BTC)
            ticker = symbol.split('-')[0]
            
            url = "https://www.alphavantage.co/query"
            params = {
                'function': 'NEWS_SENTIMENT',
                'tickers': ticker,
                'apikey': api_key,
                'limit': 1000
            }
            
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            
            if 'feed' in data:
                for item in data['feed']:
                    try:
                        ts = self._parse_av_time(item.get('time_published', ''))
                        if ts is None:
                            continue
                        timestamp = ts
                        
                        if (datetime.now() - timestamp).days <= days:
                            # ê°ì • ì ìˆ˜ ì¶”ì¶œ (-1 to 1)
                            sentiment_score = 0
                            if 'overall_sentiment_score' in item:
                                try:
                                    sentiment_score = float(item['overall_sentiment_score'])
                                except:
                                    pass
                            
                            news_list.append({
                                'timestamp': timestamp.isoformat(),
                                'title': item.get('title', ''),
                                'content': item.get('summary', '') or item.get('title', ''),
                                'sentiment': sentiment_score,
                                'source': item.get('source', 'Unknown'),
                                'url': item.get('url', '')
                            })
                    except Exception as e:
                        continue
        except Exception as e:
            print(f"  Alpha Vantage ì˜¤ë¥˜: {e}")
        
        return news_list
    
    def _fetch_news_finnhub(self, symbol: str, days: int) -> List[Dict]:
        """Finnhub API ì‚¬ìš© (API í‚¤ í•„ìš”)
        - ì•”í˜¸í™”í(BTC-USD ë“±): /v1/news?category=crypto ì‚¬ìš© (company-newsëŠ” ì£¼ì‹ ì „ìš©)
        - ì£¼ì‹(AAPL ë“±): /v1/company-news ì‚¬ìš©
        """
        news_list = []
        
        api_key = (os.getenv('FINNHUB_API_KEY', '') or '').strip()
        if not api_key:
            print("  âš  FINNHUB_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("     ë¬´ë£Œ API í‚¤ëŠ” https://finnhub.io/register ì—ì„œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return news_list
        
        try:
            is_crypto = '-USD' in symbol.upper() or '-USDT' in symbol.upper()
            cutoff = (datetime.now() - timedelta(days=days)).timestamp()
            
            if is_crypto:
                # ì•”í˜¸í™”í: company-newsëŠ” ì§€ì› ì•ˆ í•¨ â†’ /v1/news?category=crypto
                url = "https://finnhub.io/api/v1/news"
                params = {'category': 'crypto', 'token': api_key}
            else:
                # ì£¼ì‹: /v1/company-news
                ticker = symbol.split('-')[0]
                url = "https://finnhub.io/api/v1/company-news"
                params = {
                    'symbol': ticker,
                    'from': (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d'),
                    'to': datetime.now().strftime('%Y-%m-%d'),
                    'token': api_key
                }
            
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            
            if isinstance(data, list):
                for item in data[:100]:
                    try:
                        ts = item.get('datetime', 0)
                        if ts and ts < cutoff:
                            continue
                        timestamp = datetime.fromtimestamp(ts) if ts else datetime.now()
                        news_list.append({
                            'timestamp': timestamp.isoformat(),
                            'title': item.get('headline', ''),
                            'content': item.get('summary', '') or item.get('headline', ''),
                            'sentiment': 0,
                            'source': item.get('source', 'Unknown'),
                            'url': item.get('url', '')
                        })
                    except Exception:
                        continue
        except Exception as e:
            print(f"  Finnhub ì˜¤ë¥˜: {e}")
        
        return news_list
    
    def train(self, price_data: pd.DataFrame, news_data: List[Dict],
              epochs: int = 50, batch_size: int = 32, lr: float = 0.001):
        """ëª¨ë¸ í•™ìŠµ"""
        print(f"ì¥ì¹˜ ì •ë³´: {self.device}")
        if torch.cuda.is_available():
            print(f"GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}")
            print(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
        else:
            print("GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ í•™ìŠµí•©ë‹ˆë‹¤.")
            print("ë” ë¹ ë¥¸ í•™ìŠµì„ ìœ„í•´ Google Colab ì‚¬ìš©ì„ ê³ ë ¤í•´ë³´ì„¸ìš” (ì„¤ì • ë°©ë²•ì€ README ì°¸ì¡°)")
        
        print("ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
        dataset = PriceNewsDataset(price_data, news_data, device=self.device, 
                                   embedding_model=self.embedding_model)
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, 
                               num_workers=0 if self.device.type == 'cuda' else 2)
        
        # ì •ê·œí™” íŒŒë¼ë¯¸í„° ì €ì¥
        self.price_mean = dataset.price_mean
        self.price_std = dataset.price_std
        
        # ëª¨ë¸ ì´ˆê¸°í™” (ì„ë² ë”© ì°¨ì›ì„ ë°ì´í„°ì…‹ì—ì„œ ê°€ì ¸ì˜´)
        self.model = PriceNewsGenerator(
            news_embedding_dim=dataset.embedding_dim
        ).to(self.device)
        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)
        criterion = nn.MSELoss()
        
        print(f"í•™ìŠµ ì‹œì‘ (ì¥ì¹˜: {self.device})...")
        self.model.train()
        
        for epoch in range(epochs):
            total_loss = 0
            for batch in dataloader:
                price_seq = batch['price_sequence'].to(self.device)
                news_emb = batch['news_embedding'].to(self.device)
                target = batch['target'].to(self.device)
                
                optimizer.zero_grad()
                output = self.model(price_seq, news_emb)  # [B, 1, 1]
                # targetê³¼ ì°¨ì› ë§ì¶”ê¸°: targetì€ [B, 1], outputì€ [B, 1, 1]
                target_reshaped = target.unsqueeze(-1) if target.dim() == 2 else target  # [B, 1, 1]
                loss = criterion(output, target_reshaped)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
                optimizer.step()
                
                total_loss += loss.item()
            
            avg_loss = total_loss / len(dataloader)
            if (epoch + 1) % 10 == 0:
                print(f"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.6f}")
    
    def generate_price(self, price_history: pd.DataFrame, news_data: List[Dict],
                      steps: int = 10) -> np.ndarray:
        """ìƒˆë¡œìš´ ê°€ê²© ìƒì„±"""
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. train()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        self.model.eval()
        
        # ì •ê·œí™”
        normalized = (price_history[['open', 'high', 'low', 'close', 'volume']] 
                     - self.price_mean) / (self.price_std + 1e-8)
        
        generated_prices = []
        current_seq = torch.FloatTensor(normalized.values[-60:]).unsqueeze(0).to(self.device)
        
        # ë‰´ìŠ¤ ì„ë² ë”© ê³„ì‚°
        dataset = PriceNewsDataset(price_history, news_data, device=self.device,
                                   embedding_model=self.embedding_model)
        news_emb = dataset._get_news_embedding(news_data).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            for _ in range(steps):
                output = self.model(current_seq, news_emb)
                pred_price = output[0, -1, 0].cpu().item()
                generated_prices.append(pred_price)
                
                # ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸ (ìƒˆë¡œìš´ ì˜ˆì¸¡ê°’ ì¶”ê°€)
                new_row = normalized.iloc[-1].copy()
                new_row['close'] = pred_price
                new_row_tensor = torch.FloatTensor(new_row.values).unsqueeze(0).unsqueeze(0)
                current_seq = torch.cat([current_seq[:, 1:, :], new_row_tensor], dim=1)
        
        # ì—­ì •ê·œí™”
        generated_prices = np.array(generated_prices) * self.price_std['close'] + self.price_mean['close']
        
        return generated_prices
    
    def save_model(self, path: str):
        """ëª¨ë¸ ì €ì¥"""
        # ì„ë² ë”© ì°¨ì› ê°€ì ¸ì˜¤ê¸°
        embedding_dim = self.model.news_projection.in_features if self.model else 768
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'price_mean': self.price_mean,
            'price_std': self.price_std,
            'embedding_model': self.embedding_model,
            'embedding_dim': embedding_dim
        }, path)
        print(f"ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {path}")
    
    def load_model(self, path: str):
        """ëª¨ë¸ ë¡œë“œ"""
        checkpoint = torch.load(path, map_location=self.device)
        
        # ì €ì¥ëœ ì„ë² ë”© ëª¨ë¸ ì •ë³´ ì‚¬ìš© (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
        if 'embedding_model' in checkpoint:
            self.embedding_model = checkpoint['embedding_model']
        embedding_dim = checkpoint.get('embedding_dim', 768)
        
        self.model = PriceNewsGenerator(news_embedding_dim=embedding_dim).to(self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.price_mean = checkpoint['price_mean']
        self.price_std = checkpoint['price_std']
        print(f"ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤: {path}")
        if 'embedding_model' in checkpoint:
            print(f"  ì„ë² ë”© ëª¨ë¸: {checkpoint['embedding_model']}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ì£¼ì‹/ì½”ì¸ ê°€ê²© ìƒì„±ê¸° (LLM ê¸°ë°˜)")
    print("=" * 60)
    
    # ìƒì„±ê¸° ì´ˆê¸°í™”
    generator = StockPriceGenerator()
    
    # ì˜ˆì‹œ: ë¹„íŠ¸ì½”ì¸ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘
    print("\n1. ë°ì´í„° ìˆ˜ì§‘")
    price_data = generator.collect_price_data('BTC-USD', period='1y', interval='1h')
    print(f"ìˆ˜ì§‘ëœ ê°€ê²© ë°ì´í„°: {len(price_data)}ê°œ")
    
    # ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ (ì‹¤ì œë¡œëŠ” APIë¥¼ í†µí•´ ìˆ˜ì§‘í•´ì•¼ í•¨)
    news_data = generator.collect_news_data('BTC-USD', days=365)
    print(f"ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë°ì´í„°: {len(news_data)}ê°œ")
    
    # ëª¨ë¸ í•™ìŠµ
    print("\n2. ëª¨ë¸ í•™ìŠµ")
    if len(news_data) == 0:
        print("ê²½ê³ : ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê°€ê²© ë°ì´í„°ë§Œìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.")
        # ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì§„í–‰
        news_data = [{'timestamp': price_data.iloc[i]['datetime'], 
                     'title': '', 'content': '', 'sentiment': 0} 
                    for i in range(len(price_data))]
    
    generator.train(price_data, news_data, epochs=50, batch_size=32)
    
    # ëª¨ë¸ ì €ì¥
    print("\n3. ëª¨ë¸ ì €ì¥")
    generator.save_model('price_generator_model.pt')
    
    # ê°€ê²© ìƒì„± ì˜ˆì‹œ
    print("\n4. ê°€ê²© ìƒì„± í…ŒìŠ¤íŠ¸")
    recent_prices = price_data.tail(100)
    generated = generator.generate_price(recent_prices, news_data[-10:], steps=10)
    print(f"ìƒì„±ëœ ê°€ê²© (ë‹¤ìŒ 10ë‹¨ê³„):")
    for i, price in enumerate(generated):
        print(f"  Step {i+1}: ${price:.2f}")


if __name__ == "__main__":
    main()
